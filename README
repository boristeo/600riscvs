1mb "L1" sram per core, banked
120 cores
5 cpus per core (1 din 3 compute 1 dout) - 600 riscvs!!!
tile + vector engines?
332 fp8 TOPS*** possibly 276 fp8 332 fp4? what type of fp8?
8gb dram

---


lightmetal - flatbuffer capture and replay of traces!!!

plan of action:
1) try to turn loopback example into lightmetal flatbuf
2) verify that it runs, find minimum amount of their library necessary (device enumeration, running flatbuf)
3) inspect flatbuf internals, find kernel, try to recreate from scratch.
4) verify that my kernel functionally identical
5) repeat 3,4 for increasingly more complex metal programs (two kernels, using accel, etc)

---

New update:

lightmetal is useless. Doesn't allow tracing anything fun.

Found new way in - llrt. Has nice, real commands for address translation, firmware loading, looks like even kernel jit?

all the api/tt-metalium/tt_* apis seem especially sane



gs_hal.cpp
---

processor class - one of BRISC, NRISC, TRISC (no ERISC on grayskull)
processor type - unused for BRISC and NRISC, 0-2 for TRISC
HalJitBuildConfig with addresses for each subcore stored like this in processor_classes: [[BRISC],[NRISC],[TRISC0,TRISC1,TRISC2]]

relocate_func_ changes MEM_LOCAL_BASE offset to local_init_addr, MEM_NRISC_IRAM_BASE offset to MEM_NRISC_IRAM_L1_BASE (what's an IRAM?)

NOCS have some regs in NOC_OVERLAY, NOC0_REGS, NOC1_REGa. Hopefully I don't mess with these directly


tt_memory.cpp: Has way to load elf file from path. Watch out for this to see where kernels are stored by compiler
llrt.cpp: get_risc_binary
test_compile_sets_kernel_binaries.cpp: I think this is what I want

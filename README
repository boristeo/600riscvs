1mb "L1" sram per core, banked
120 cores
5 cpus per core (1 din 3 compute 1 dout) - 600 riscvs!!!
tile + vector engines?
332 fp8 TOPS*** possibly 276 fp8 332 fp4? what type of fp8?
8gb dram

---


lightmetal - flatbuffer capture and replay of traces!!!

plan of action:
1) try to turn loopback example into lightmetal flatbuf
2) verify that it runs, find minimum amount of their library necessary (device enumeration, running flatbuf)
3) inspect flatbuf internals, find kernel, try to recreate from scratch.
4) verify that my kernel functionally identical
5) repeat 3,4 for increasingly more complex metal programs (two kernels, using accel, etc)

---

New update:

lightmetal is useless. Doesn't allow tracing anything fun.
Found new way in - llrt. Has nice, real commands for address translation, firmware loading, looks like even kernel jit?
all the api/tt-metalium/tt_* apis seem especially sane

gs_hal.cpp
---

processor class - one of BRISC, NRISC, TRISC (no ERISC on grayskull)
processor type - unused for BRISC and NRISC, 0-2 for TRISC
HalJitBuildConfig with addresses for each subcore stored like this in processor_classes: [[BRISC],[NRISC],[TRISC0,TRISC1,TRISC2]]
relocate_func_ changes MEM_LOCAL_BASE offset to local_init_addr, MEM_NRISC_IRAM_BASE offset to MEM_NRISC_IRAM_L1_BASE (what's an IRAM?)
NOCS have some regs in NOC_OVERLAY, NOC0_REGS, NOC1_REGa. Hopefully I don't mess with these directly

tt_memory.cpp: Has way to load elf file from path. Watch out for this to see where kernels are stored by compiler
llrt.cpp: get_risc_binary
test_compile_sets_kernel_binaries.cpp: I think this is what I want

---

No escape linking to full tt-metal. Had to steal some warning silence (SMH:/) flags and for some reason tt-metal default is to link to libc++?
But it looks like now things work. Time for a bit of ablation...

---

tt_umd - user mode driver?

Many good things. Wait so all reads and writes are through the (code mentions 3 but I see just one 512mb o.o) BAR? Any DMA support??
And how does all this relate to the hugepages I had to enable during setup... I'm confused

Also what's up with these TLBs? 

dev_msgs.h packed little structures containing various messages for device.

init procedure:

1) 256 bytes to 0x2a8 through 12,11(!) Some sort of reset?

device_bank_to_noc_tables:

16*2 + 256*2 + 8*4 + 128*4

launch_msg_t == kernel_config_msg_t -> 80 bytes; * launch_msg_num_entries (8) -> 640 bytes

go_msg_t -> 4 bytes

NUM_NOCS = 2
NUM_DRAM_BANKS = 8
NUM_L1_BANKS = 64?

extern uint16_t dram_bank_to_noc_xy[NUM_NOCS][NUM_DRAM_BANKS];
extern int32_t bank_to_dram_offset[NUM_DRAM_BANKS];
extern uint16_t l1_bank_to_noc_xy[NUM_NOCS][NUM_L1_BANKS];
extern int32_t bank_to_l1_offset[NUM_L1_BANKS];

std::vector<int32_t> dram_bank_offset_map_;
std::vector<int32_t> l1_bank_offset_map_;
std::vector<uint16_t> dram_bank_to_noc_xy_;
std::vector<uint16_t> l1_bank_to_noc_xy_;

4 + 640 + 4 + 4

But hey at least the order seems correct... 


